---
title: "Le format Parquet pour la diffusion de données : un choix technique au service des utilisateurs"
authors:
  - name: Cédric Bobinec
    affiliation: Insee, Pôle ODL
    email: <cedric.bobinec@insee.fr>
  - name: Lino Galiana
    affiliation: Insee, Direction des statistiques démographiques et sociales
    email: <lino.galiana@insee.fr>
keywords: # 6 maximum
  - open data
  - open source
  - diffusion de données
domains: # utiliser la nomenclature du site (menu déroulant) 
  - Communication, open science
  - Open data, documentation, métadonnées, mise à disposition
resume: |
    La diffusion et l'exploitation de microdonnées se heurte souvent à des freins techniques liés au volume des fichiers et à la complexité de leur exploitation. Le format \texttt{Parquet}, issu à l'origine de l’écosystème big data mais s'étant diffusé bien au-delà de cette sphère, s’impose comme une alternative efficace aux formats traditionnels comme le CSV. 

    Le format Parquet présente, pour les statisticiens et data scientists, des propriétés idéales. Il s'agit d'un format \textit{open source}, associé à un écosystème dynamique principalement articulé autour des projets Arrow et DuckDB. Par rapport au \texttt{CSV}, le format \texttt{Parquet} permet d'obtenir des fichiers légers, rapides à lire et avec des métadonnées permettant aux producteurs de données de mieux guider les réutilisateurs de données. Ce format est bien intégré dans les principaux langages de traitement de données (\texttt{R}, \texttt{Python}, \texttt{Javascript}) ce qui facilite, dans les faits, l’exploitation de données sans nécessiter d’outils propriétaires ou de ressources machines importantes.

    Cette présentation reviendra sur les expériences de diffusion de données au format Parquet par l'Insee à partir des exemples des données anonymisées du recensement de la population ou la base des équipements publics. Ce choix technique, associé à un accompagnement des utilisateurs (guides, exemples de code), a permis d'accroître l'usage de ces sources qui étaient, auparavant, complexes à valoriser.  Cette communication évoquera également les implications pratiques de ce choix technique, les bonnes pratiques à mettre en oeuvre lors de l'adoption de ce format de données et les opportunités d'innovation permises par ce format.
abstract: |
    (Texte en anglais de 5 à 10 lignes)\ 
    `#lorem(30)`{=typst}
bibliography: references.bib
format:
  jms2025-typst:
    logo:
      location: center-top # ne pas modifier
      width: 160mm # ne pas modifier
    mainfont: "tex gyre heros" # peut être modifié pour "calibri" sous windows, voir le script install-fonts.sh
    footer: 15^e^ édition des journées de méthodologie statistique de l'Insee (JMS 2025) # ne pas modifier
    section-numbering: 1.1.1.
    keep-typ: true
---

Parmi les nombreuses innovations techniques ayant émergé depuis les années 2010 dans l'écosystème de la donnée, le format `Parquet` fait parti de celles ayant connues une adoption large parmi les _data scientists_ et statisticiens. Initialement conçu pour répondre à aux besoins des plateformes _big data_ comme [Hadoop](https://fr.wikipedia.org/wiki/Hadoop) - réduction du volume de stockage et du temps de lecture des données - celui-ci s'est diffusé au-delà de cette sphère et a même survécu à la plupart des technologies _big data_ qui sont, depuis, tombées en désuétude [@tigani2023big].

Plusieurs acteurs majeurs de l'écosystème de l'intelligence artificielle, notamment [HuggingFace](https://huggingface.co/), ont fait de `Parquet` la pierre angulaire de leur système de stockage de données. Dans le domaine de la diffusion de données, où se rencontrent des publics aux attentes et compétences techniques diverses, l'adoption de ce format a été plus tardive. Si la plateforme communautaire `data.gouv` recense depuis plusieurs années des `Parquet` créés par des utilisateurs experts pour faciliter l'usage de certains jeux de données, la statistique publique ne s'est mise à diffuser, d'elle-même, que récemment des fichiers `Parquet`. Depuis la diffusion en 2023 par l'Insee des données détaillées du répertoire électoral unique (REU) puis du recensement de la population (RP) dans ce format de données, permettant de simplifier l'usage de ces sources de données volumineuses, de nombreuses sources de la statistique publique ont été publiées dans ce format.

Nous reviendrons d'abord sur les propriétés techniques intéressantes de ce format qui expliquent sa popularité, sans être spécifique aux problématiques de diffusion de données (@sec-1). Nous évoquerons ensuite la manière dont les librairies à l'état de l'art permettent de consommer de manière assez efficace ce type de fichier, ce qui en fait un fichier de diffusion intéressant (@sec-2). Nous reviendrons ensuite sur les expériences de diffusion au format `Parquet` et évoquerons quelques bonnes pratiques pour la diffusion de données et l'accompagnement des utilisateurs (@sec-3). Nous terminerons par les perspectives qu'ouvre l'adoption plus large de `Parquet` pour partager des données dans une perspective de _datavisualisations_ automatiques ou de plateformes de données à destination de praticiens (@sec-4). 


Nous présenterons d’abord les propriétés techniques du format `Parquet` qui expliquent sa popularité, bien qu'elles ne soient pas propres aux problématiques de diffusion de données (@sec-1). Nous aborderons ensuite les outils et bibliothèques à l'état de l’art permettant de consommer efficacement ce type de fichiers, faisant du `Parquet` un format particulièrement adapté à la diffusion de données (@sec-2).  
Nous reviendrons sur les retours d'expérience liés à la diffusion de données publiques en `Parquet` et proposerons quelques bonnes pratiques pour leur mise à disposition et l'accompagnement des utilisateurs (@sec-3). Enfin, nous évoquerons les perspectives qu'ouvre une adoption plus large de ce format, notamment pour la mise en place de _datavisualisations_ automatiques ou l'adoption de plateformes de données à destination des praticiens (@sec-4).

# Retour sur les proriétés techniques du format `Parquet`

## Les deux approches : le fichier ou la base de données

Dans le domaine du stockage et de la mise à disposition de données, deux logiques dominent : la base de données ou le fichier. Ces deux logiques diffèrent fortement dans la manière dont l'information est organisée, accessible et modifiable par un client qui la consomme. 

Une base de données relationnelle est une manière de procéder selon une logique systémique. L'accès à la donné (en lecture comme en écriture) est gérée par un système de gestion de base de données (SGBD) qui permet :

- de stocker des ensembles cohérents de données,
- d'en permettre la mise à jour (ajout, suppression, modification),
- d'en contrôler l'accès (droits utilisateurs, types de requêtes, etc.).

Dans ces systèmes, les données sont organisées en tables reliées par des relations, souvent selon un schéma en étoile. Par exemple, une table longitudinale de données individuelles est reliée d'un côté à une table d'identifiants ménage uniques et de l'autre à une table d'identifiants entreprise unique. Le logiciel associé à la base de données fait ensuite le lien entre ces tables, souvent par le biais de requêtes `SQL`. L'un des logiciels les plus efficaces dans ce domaine est [`PostgreSQL`](https://www.postgresql.org/).

La deuxième approche est celle du fichier qui consiste à organiser l'information dans un document stocké de manière autonome sur un système de fichiers. Contrairement à la base de données, le fichier ne repose pas sur un moteur logiciel chargé d’en gérer les accès ou la cohérence : il contient directement la donnée, dans un format plus ou moins structuré selon les besoins.

Cette approche favorise la simplicité et la portabilité. Les fichiers peuvent être partagés, copiés ou archivés sans dépendre d’une infrastructure spécifique.
Ils ne nécessitent pas l'installation ou le maintien d’un logiciel de gestion spécialisé : un simple _file system_, déjà présent sur tout système d’exploitation, suffit à y accéder. Leur lecture ne nécessite qu'un outil adapté au format utilisé. 

Le succès croissant des fichiers dans l’écosystème de la data science s’explique par plusieurs facteurs techniques et pratiques qui les rendent particulièrement adaptés aux usages analytiques modernes.

En premier lieu, les fichiers sont beaucoup plus légers à manipuler que les bases de données. Ils ne nécessitent pas l'installation ou le maintien d’un logiciel de gestion spécialisé : un simple _file system_, déjà présent sur tout système d’exploitation, suffit à y accéder. En ce qui concerne la lecture, il s'agit d'avoir un outil adapté au format utilisé. Ceci rend l'approche par les fichiers particulièrement souple et explique le succès de formats plats comme le `CSV` (lisible par n'importe quel éditeur de texte), `JSON` (lisible par n'importe quel navigateur web) ou, plus récemment, le format `Parquet`.


La principale raison pour laquelle les fichiers sont souvent privilégiés par rapport aux SGBD réside dans la nature des opérations effectuées. Les bases de données relationnelles prennent tout leur sens lorsque l'on doit gérer des écritures fréquentes ou des mises à jour complexes sur des ensembles de données structurés — c’est-à-dire dans une logique applicative, où la donnée évolue continuellement (ajout, modification, suppression). À l'inverse, dans un contexte analytique, on se contente généralement de lire et de manipuler temporairement des données sans modifier la source. L'objectif est d’interroger, d’agréger, de filtrer — pas de pérenniser les changements. Pour ce type d’usage, les fichiers (notamment dans des formats optimisés comme `Parquet`, comme nous allons le voir) sont parfaitement adaptés : ils offrent une lecture rapide, une portabilité élevée et n'imposent pas l'intermédiation d’un moteur de base de données.


## 

# Les librairies 

# La diffusion du RP 

## Retour sur la diffusion

## Bonnes pratiques

sorting

# Perspectives